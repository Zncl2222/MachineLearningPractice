{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNpzhh7uevNahkX6fMdAVzV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zncl2222/MachineLearningPractice/blob/pytorch_tutorial/00_pytorch_fundamentals_exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise1\n",
        "Documentation reading - A big part of deep learning (and learning to code in general) is getting familiar with the documentation of a certain framework you're using. We'll be using the PyTorch documentation a lot throughout the rest of this course. So I'd recommend spending 10-minutes reading the following (it's okay if you don't get some things for now, the focus is not yet full understanding, it's awareness). See the documentation on torch.Tensor and for torch.cuda.\n"
      ],
      "metadata": {
        "id": "Zha2-vhVOdQL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t0mQBk-sOgcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exercise2\n",
        "Create a random tensor with shape (7, 7)."
      ],
      "metadata": {
        "id": "57VClwrUOslT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "tensor = torch.rand(size=(7, 7))\n",
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYfrKXjaOwnB",
        "outputId": "e8da907d-bfc7-47c3-a297-e4a7d9cfc21d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4279, 0.5260, 0.6442, 0.0946, 0.8218, 0.4946, 0.4604],\n",
              "        [0.7183, 0.2247, 0.4648, 0.6661, 0.7739, 0.0592, 0.4168],\n",
              "        [0.6216, 0.8256, 0.5386, 0.5871, 0.0882, 0.2693, 0.8291],\n",
              "        [0.9338, 0.8786, 0.0810, 0.9722, 0.0681, 0.2928, 0.3483],\n",
              "        [0.1466, 0.3005, 0.0100, 0.9138, 0.0801, 0.4617, 0.5666],\n",
              "        [0.2809, 0.1868, 0.7565, 0.6641, 0.4781, 0.3702, 0.5200],\n",
              "        [0.8726, 0.7145, 0.1622, 0.7112, 0.2732, 0.6751, 0.9106]])"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exercise3\n",
        "Perform a matrix multiplication on the tensor from 2 with another random tensor with shape (1, 7) (hint: you may have to transpose the second tensor)."
      ],
      "metadata": {
        "id": "CjoXCWVFPD9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zero_tensor = torch.rand(size=(1, 7))\n",
        "result_tensor = tensor.reshape(49, 1).matmul(zero_tensor)\n",
        "result_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jceG5JoaPFuf",
        "outputId": "0c1a2bda-9f5c-4245-d59e-a58b9f85ad66"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[6.0124e-02, 2.5806e-01, 5.5850e-02, 1.5454e-01, 1.3955e-02, 4.0442e-01,\n",
              "         1.2000e-01],\n",
              "        [3.5169e-02, 1.5095e-01, 3.2669e-02, 9.0394e-02, 8.1630e-03, 2.3656e-01,\n",
              "         7.0195e-02],\n",
              "        [2.2874e-02, 9.8177e-02, 2.1248e-02, 5.8793e-02, 5.3092e-03, 1.5386e-01,\n",
              "         4.5655e-02],\n",
              "        [1.0265e-01, 4.4056e-01, 9.5350e-02, 2.6383e-01, 2.3825e-02, 6.9045e-01,\n",
              "         2.0487e-01],\n",
              "        [3.4579e-02, 1.4841e-01, 3.2121e-02, 8.8877e-02, 8.0260e-03, 2.3259e-01,\n",
              "         6.9017e-02],\n",
              "        [1.1700e-01, 5.0218e-01, 1.0869e-01, 3.0073e-01, 2.7157e-02, 7.8702e-01,\n",
              "         2.3353e-01],\n",
              "        [3.6562e-02, 1.5693e-01, 3.3964e-02, 9.3976e-02, 8.4864e-03, 2.4594e-01,\n",
              "         7.2976e-02],\n",
              "        [5.3424e-02, 2.2930e-01, 4.9626e-02, 1.3731e-01, 1.2400e-02, 3.5935e-01,\n",
              "         1.0663e-01],\n",
              "        [1.0233e-01, 4.3921e-01, 9.5057e-02, 2.6302e-01, 2.3752e-02, 6.8833e-01,\n",
              "         2.0424e-01],\n",
              "        [5.8450e-02, 2.5087e-01, 5.4295e-02, 1.5023e-01, 1.3567e-02, 3.9316e-01,\n",
              "         1.1666e-01],\n",
              "        [7.3773e-02, 3.1664e-01, 6.8529e-02, 1.8962e-01, 1.7123e-02, 4.9623e-01,\n",
              "         1.4724e-01],\n",
              "        [1.1920e-01, 5.1161e-01, 1.1073e-01, 3.0638e-01, 2.7667e-02, 8.0180e-01,\n",
              "         2.3791e-01],\n",
              "        [4.9918e-02, 2.1425e-01, 4.6370e-02, 1.2830e-01, 1.1586e-02, 3.3577e-01,\n",
              "         9.9633e-02],\n",
              "        [7.5082e-02, 3.2226e-01, 6.9745e-02, 1.9298e-01, 1.7427e-02, 5.0504e-01,\n",
              "         1.4986e-01],\n",
              "        [2.5382e-02, 1.0894e-01, 2.3578e-02, 6.5239e-02, 5.8913e-03, 1.7073e-01,\n",
              "         5.0661e-02],\n",
              "        [3.5563e-02, 1.5264e-01, 3.3035e-02, 9.1407e-02, 8.2544e-03, 2.3921e-01,\n",
              "         7.0981e-02],\n",
              "        [9.5913e-02, 4.1166e-01, 8.9095e-02, 2.4652e-01, 2.2262e-02, 6.4516e-01,\n",
              "         1.9144e-01],\n",
              "        [1.2184e-01, 5.2295e-01, 1.1318e-01, 3.1317e-01, 2.8280e-02, 8.1957e-01,\n",
              "         2.4319e-01],\n",
              "        [4.1756e-02, 1.7922e-01, 3.8788e-02, 1.0732e-01, 9.6918e-03, 2.8087e-01,\n",
              "         8.3342e-02],\n",
              "        [4.5283e-02, 1.9436e-01, 4.2064e-02, 1.1639e-01, 1.0510e-02, 3.0459e-01,\n",
              "         9.0381e-02],\n",
              "        [3.6989e-02, 1.5876e-01, 3.4360e-02, 9.5073e-02, 8.5855e-03, 2.4881e-01,\n",
              "         7.3828e-02],\n",
              "        [9.2762e-03, 3.9814e-02, 8.6169e-03, 2.3843e-02, 2.1531e-03, 6.2396e-02,\n",
              "         1.8515e-02],\n",
              "        [9.5878e-02, 4.1151e-01, 8.9063e-02, 2.4643e-01, 2.2254e-02, 6.4492e-01,\n",
              "         1.9137e-01],\n",
              "        [6.1271e-03, 2.6298e-02, 5.6916e-03, 1.5748e-02, 1.4221e-03, 4.1214e-02,\n",
              "         1.2229e-02],\n",
              "        [9.6712e-02, 4.1509e-01, 8.9838e-02, 2.4858e-01, 2.2448e-02, 6.5053e-01,\n",
              "         1.9303e-01],\n",
              "        [3.3398e-03, 1.4335e-02, 3.1024e-03, 8.5843e-03, 7.7520e-04, 2.2465e-02,\n",
              "         6.6661e-03],\n",
              "        [9.2987e-02, 3.9911e-01, 8.6377e-02, 2.3900e-01, 2.1583e-02, 6.2548e-01,\n",
              "         1.8560e-01],\n",
              "        [6.1611e-02, 2.6444e-01, 5.7231e-02, 1.5836e-01, 1.4300e-02, 4.1442e-01,\n",
              "         1.2297e-01],\n",
              "        [9.7214e-02, 4.1725e-01, 9.0304e-02, 2.4987e-01, 2.2564e-02, 6.5391e-01,\n",
              "         1.9403e-01],\n",
              "        [3.1257e-02, 1.3416e-01, 2.9036e-02, 8.0340e-02, 7.2550e-03, 2.1025e-01,\n",
              "         6.2388e-02],\n",
              "        [1.2770e-01, 5.4808e-01, 1.1862e-01, 3.2822e-01, 2.9639e-02, 8.5896e-01,\n",
              "         2.5488e-01],\n",
              "        [1.2367e-01, 5.3079e-01, 1.1488e-01, 3.1786e-01, 2.8704e-02, 8.3185e-01,\n",
              "         2.4683e-01],\n",
              "        [7.8794e-02, 3.3819e-01, 7.3193e-02, 2.0252e-01, 1.8289e-02, 5.3001e-01,\n",
              "         1.5727e-01],\n",
              "        [2.9621e-02, 1.2714e-01, 2.7516e-02, 7.6135e-02, 6.8753e-03, 1.9925e-01,\n",
              "         5.9122e-02],\n",
              "        [1.1002e-01, 4.7221e-01, 1.0220e-01, 2.8278e-01, 2.5536e-02, 7.4004e-01,\n",
              "         2.1959e-01],\n",
              "        [3.3910e-02, 1.4554e-01, 3.1500e-02, 8.7158e-02, 7.8707e-03, 2.2809e-01,\n",
              "         6.7682e-02],\n",
              "        [1.8086e-02, 7.7628e-02, 1.6801e-02, 4.6487e-02, 4.1980e-03, 1.2166e-01,\n",
              "         3.6099e-02],\n",
              "        [8.2873e-02, 3.5570e-01, 7.6982e-02, 2.1301e-01, 1.9235e-02, 5.5744e-01,\n",
              "         1.6541e-01],\n",
              "        [1.1750e-01, 5.0430e-01, 1.0914e-01, 3.0200e-01, 2.7272e-02, 7.9034e-01,\n",
              "         2.3451e-01],\n",
              "        [1.7608e-02, 7.5576e-02, 1.6357e-02, 4.5258e-02, 4.0870e-03, 1.1844e-01,\n",
              "         3.5145e-02],\n",
              "        [1.2012e-01, 5.1557e-01, 1.1158e-01, 3.0875e-01, 2.7881e-02, 8.0800e-01,\n",
              "         2.3975e-01],\n",
              "        [5.2843e-03, 2.2680e-02, 4.9087e-03, 1.3582e-02, 1.2265e-03, 3.5545e-02,\n",
              "         1.0547e-02],\n",
              "        [1.1517e-01, 4.9432e-01, 1.0698e-01, 2.9602e-01, 2.6732e-02, 7.7469e-01,\n",
              "         2.2987e-01],\n",
              "        [8.0309e-02, 3.4469e-01, 7.4601e-02, 2.0642e-01, 1.8640e-02, 5.4020e-01,\n",
              "         1.6029e-01],\n",
              "        [1.0101e-01, 4.3356e-01, 9.3833e-02, 2.5963e-01, 2.3446e-02, 6.7947e-01,\n",
              "         2.0162e-01],\n",
              "        [2.7385e-02, 1.1754e-01, 2.5438e-02, 7.0387e-02, 6.3562e-03, 1.8420e-01,\n",
              "         5.4658e-02],\n",
              "        [5.3521e-02, 2.2971e-01, 4.9716e-02, 1.3756e-01, 1.2423e-02, 3.6001e-01,\n",
              "         1.0682e-01],\n",
              "        [3.0371e-02, 1.3036e-01, 2.8212e-02, 7.8063e-02, 7.0494e-03, 2.0429e-01,\n",
              "         6.0619e-02],\n",
              "        [4.3381e-02, 1.8620e-01, 4.0298e-02, 1.1150e-01, 1.0069e-02, 2.9180e-01,\n",
              "         8.6586e-02]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exercise4\n",
        "Set the random seed to 0 and do exercises 2 & 3 over again."
      ],
      "metadata": {
        "id": "PmhG1sczPkw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RAND_SEED = 123\n",
        "torch.manual_seed(RAND_SEED)\n",
        "tensor_a = torch.rand(7, 7)\n",
        "torch.manual_seed(RAND_SEED)\n",
        "tensor_b = torch.rand(1, 7)\n",
        "\n",
        "tensor_c = tensor_a.reshape(49, 1).mm(tensor_b)\n",
        "tensor_c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMviJOtRPo10",
        "outputId": "01966571-e4c0-491c-c627-7b3a77d8d4b0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0877, 0.1530, 0.0745, 0.2039, 0.0219, 0.2566, 0.0404],\n",
              "        [0.1530, 0.2668, 0.1300, 0.3557, 0.0382, 0.4476, 0.0706],\n",
              "        [0.0745, 0.1300, 0.0633, 0.1733, 0.0186, 0.2181, 0.0344],\n",
              "        [0.2039, 0.3557, 0.1733, 0.4741, 0.0509, 0.5966, 0.0940],\n",
              "        [0.0219, 0.0382, 0.0186, 0.0509, 0.0055, 0.0641, 0.0101],\n",
              "        [0.2566, 0.4476, 0.2181, 0.5966, 0.0641, 0.7509, 0.1183],\n",
              "        [0.0404, 0.0706, 0.0344, 0.0940, 0.0101, 0.1183, 0.0187],\n",
              "        [0.0303, 0.0529, 0.0258, 0.0706, 0.0076, 0.0888, 0.0140],\n",
              "        [0.0545, 0.0951, 0.0463, 0.1267, 0.0136, 0.1595, 0.0251],\n",
              "        [0.2151, 0.3753, 0.1828, 0.5002, 0.0537, 0.6295, 0.0992],\n",
              "        [0.0934, 0.1628, 0.0793, 0.2171, 0.0233, 0.2732, 0.0431],\n",
              "        [0.2035, 0.3549, 0.1729, 0.4731, 0.0508, 0.5954, 0.0938],\n",
              "        [0.0224, 0.0391, 0.0190, 0.0521, 0.0056, 0.0655, 0.0103],\n",
              "        [0.0582, 0.1016, 0.0495, 0.1354, 0.0145, 0.1704, 0.0269],\n",
              "        [0.0937, 0.1634, 0.0796, 0.2179, 0.0234, 0.2742, 0.0432],\n",
              "        [0.1190, 0.2075, 0.1011, 0.2766, 0.0297, 0.3481, 0.0549],\n",
              "        [0.0351, 0.0612, 0.0298, 0.0816, 0.0088, 0.1027, 0.0162],\n",
              "        [0.2450, 0.4274, 0.2082, 0.5697, 0.0612, 0.7170, 0.1130],\n",
              "        [0.1131, 0.1974, 0.0962, 0.2631, 0.0283, 0.3311, 0.0522],\n",
              "        [0.1956, 0.3412, 0.1662, 0.4548, 0.0489, 0.5723, 0.0902],\n",
              "        [0.2528, 0.4409, 0.2148, 0.5877, 0.0631, 0.7396, 0.1166],\n",
              "        [0.1756, 0.3064, 0.1493, 0.4084, 0.0439, 0.5140, 0.0810],\n",
              "        [0.1885, 0.3289, 0.1602, 0.4384, 0.0471, 0.5517, 0.0870],\n",
              "        [0.2910, 0.5076, 0.2473, 0.6766, 0.0727, 0.8515, 0.1342],\n",
              "        [0.0813, 0.1418, 0.0691, 0.1890, 0.0203, 0.2379, 0.0375],\n",
              "        [0.1950, 0.3401, 0.1657, 0.4533, 0.0487, 0.5705, 0.0899],\n",
              "        [0.0822, 0.1434, 0.0698, 0.1911, 0.0205, 0.2405, 0.0379],\n",
              "        [0.2539, 0.4429, 0.2158, 0.5903, 0.0634, 0.7429, 0.1171],\n",
              "        [0.2663, 0.4646, 0.2263, 0.6192, 0.0665, 0.7793, 0.1228],\n",
              "        [0.0116, 0.0202, 0.0098, 0.0269, 0.0029, 0.0338, 0.0053],\n",
              "        [0.2744, 0.4788, 0.2333, 0.6382, 0.0686, 0.8031, 0.1266],\n",
              "        [0.2188, 0.3816, 0.1859, 0.5087, 0.0546, 0.6401, 0.1009],\n",
              "        [0.2126, 0.3708, 0.1807, 0.4943, 0.0531, 0.6221, 0.0980],\n",
              "        [0.2090, 0.3646, 0.1776, 0.4860, 0.0522, 0.6116, 0.0964],\n",
              "        [0.2711, 0.4730, 0.2304, 0.6305, 0.0677, 0.7934, 0.1251],\n",
              "        [0.1285, 0.2242, 0.1092, 0.2988, 0.0321, 0.3761, 0.0593],\n",
              "        [0.0228, 0.0399, 0.0194, 0.0531, 0.0057, 0.0669, 0.0105],\n",
              "        [0.1056, 0.1842, 0.0897, 0.2455, 0.0264, 0.3089, 0.0487],\n",
              "        [0.0438, 0.0764, 0.0372, 0.1018, 0.0109, 0.1281, 0.0202],\n",
              "        [0.1578, 0.2754, 0.1342, 0.3670, 0.0394, 0.4619, 0.0728],\n",
              "        [0.1204, 0.2101, 0.1023, 0.2800, 0.0301, 0.3524, 0.0555],\n",
              "        [0.0686, 0.1197, 0.0583, 0.1596, 0.0171, 0.2009, 0.0317],\n",
              "        [0.1346, 0.2348, 0.1144, 0.3130, 0.0336, 0.3939, 0.0621],\n",
              "        [0.2883, 0.5030, 0.2451, 0.6704, 0.0720, 0.8437, 0.1330],\n",
              "        [0.1364, 0.2379, 0.1159, 0.3171, 0.0341, 0.3991, 0.0629],\n",
              "        [0.1528, 0.2665, 0.1298, 0.3552, 0.0382, 0.4470, 0.0705],\n",
              "        [0.1250, 0.2180, 0.1062, 0.2906, 0.0312, 0.3657, 0.0576],\n",
              "        [0.1713, 0.2989, 0.1456, 0.3984, 0.0428, 0.5014, 0.0790],\n",
              "        [0.2800, 0.4884, 0.2380, 0.6510, 0.0699, 0.8193, 0.1291]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exercise5\n",
        "Speaking of random seeds, we saw how to set it with torch.manual_seed() but is there a GPU equivalent? (hint: you'll need to look into the documentation for torch.cuda for this one). If there is, set the GPU random seed to 1234."
      ],
      "metadata": {
        "id": "LBeCfbecQGil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RAND_SEED = 654\n",
        "torch.cuda.manual_seed(RAND_SEED)\n",
        "gpu_tensor = torch.rand((3, 3), device='cuda')\n",
        "torch.cuda.manual_seed(RAND_SEED)\n",
        "gpu_tensor2 = torch.rand((3, 3), device='cuda')\n",
        "gpu_tensor, gpu_tensor2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxIplbPlQcdk",
        "outputId": "f70e1ef1-6d33-4c3f-c5e0-2018ae202fb8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.5826, 0.1039, 0.7702],\n",
              "         [0.8087, 0.5020, 0.7764],\n",
              "         [0.8980, 0.8438, 0.3329]], device='cuda:0'),\n",
              " tensor([[0.5826, 0.1039, 0.7702],\n",
              "         [0.8087, 0.5020, 0.7764],\n",
              "         [0.8980, 0.8438, 0.3329]], device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exercise6\n",
        "Create two random tensors of shape (2, 3) and send them both to the GPU (you'll need access to a GPU for this). Set torch.manual_seed(1234) when creating the tensors (this doesn't have to be the GPU random seed)."
      ],
      "metadata": {
        "id": "qaRbDx1tRZBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RAND_SEED = 1234\n",
        "torch.manual_seed(RAND_SEED)\n",
        "tensor = torch.rand((2, 3), device='cpu')\n",
        "gpu_tensor = tensor.to('cuda')\n",
        "torch.manual_seed(RAND_SEED)\n",
        "tensor2 = torch.rand((2, 3), device='cpu')\n",
        "gpu_tensor2 = tensor.to('cuda')\n",
        "gpu_tensor, gpu_tensor2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulxbq2QBRbyJ",
        "outputId": "cfe5b984-93b9-4bc6-9359-434629746beb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.0290, 0.4019, 0.2598],\n",
              "         [0.3666, 0.0583, 0.7006]], device='cuda:0'),\n",
              " tensor([[0.0290, 0.4019, 0.2598],\n",
              "         [0.3666, 0.0583, 0.7006]], device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exercise7\n",
        "Perform a matrix multiplication on the tensors you created in 6 (again, you may have to adjust the shapes of one of the tensors)."
      ],
      "metadata": {
        "id": "5wFatC2kSD4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reshaped_tensor = gpu_tensor.reshape(3, 2)\n",
        "\n",
        "result_tensor = reshaped_tensor.mm(gpu_tensor2)\n",
        "result_tensor, result_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhWlTBMVSGiP",
        "outputId": "8a6067ad-16eb-4ae6-c32e-7f696d4ed6b8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.1482, 0.0351, 0.2891],\n",
              "         [0.1420, 0.1258, 0.3244],\n",
              "         [0.2586, 0.0643, 0.5061]], device='cuda:0'),\n",
              " torch.Size([3, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exercise 8 & 9\n",
        "Find the maximum and minimum values of the output of 7.\n",
        "Find the maximum and minimum index values of the output of 7."
      ],
      "metadata": {
        "id": "3ydnHnwHSbnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(result_tensor.max())\n",
        "print(result_tensor.min())\n",
        "print(result_tensor.argmax())\n",
        "print(result_tensor.argmin())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKGGZ-AISeMI",
        "outputId": "74d30b66-f929-4075-a5e0-89d27e01b638"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.5061, device='cuda:0')\n",
            "tensor(0.0351, device='cuda:0')\n",
            "tensor(8, device='cuda:0')\n",
            "tensor(1, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exercise 10\n",
        "Make a random tensor with shape (1, 1, 1, 10) and then create a new tensor with all the 1 dimensions removed to be left with a tensor of shape (10). Set the seed to 7 when you create it and print out the first tensor and it's shape as well as the second tensor and it's shape."
      ],
      "metadata": {
        "id": "ClTI-jQySsyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(7)\n",
        "tensor = torch.rand(size=(1, 1, 1, 10))\n",
        "tensor_squeezed = tensor.squeeze()\n",
        "print(tensor, tensor.shape)\n",
        "print(tensor_squeezed, tensor_squeezed.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHbKCEQ1SvVG",
        "outputId": "55aee65e-ed80-40a7-8a05-d0a25ce65fbb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297,\n",
            "           0.3653, 0.8513]]]]) torch.Size([1, 1, 1, 10])\n",
            "tensor([0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297, 0.3653,\n",
            "        0.8513]) torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QTlvB43qTAw0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}